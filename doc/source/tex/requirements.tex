\documentclass[
11pt, % Main document font size
a4paper, % Paper type, use 'letterpaper' for US Letter paper
oneside, % One page layout (no page indentation)
twoside, % Two page layout (page indentation for binding and different headers)
headinclude,footinclude, % Extra spacing for the header and footer
BCOR5mm, % Binding correction
]{scrartcl}

\usepackage[
nochapters, % Turn off chapters since this is an article        
beramono, % Use the Bera Mono font for monospaced text (\texttt)
eulermath,% Use the Euler font for mathematics
pdfspacing, % Makes use of pdftexâ€™ letter spacing capabilities via the microtype package
dottedtoc % Dotted lines leading to the page numbers in the table of contents
]{classicthesis} % The layout is based on the Classic Thesis style

\usepackage{arsclassica} % Modifies the Classic Thesis package
\usepackage{minted}
\usepackage{pdfpages}

\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs

\usepackage[utf8]{inputenc} % Required for including letters with accents

\usepackage{graphicx} % Required for including images
\graphicspath{{Figures/}} % Set the default folder for images
\usepackage[total={6.5in, 9.0in}]{geometry}

\usepackage{enumitem} % Required for manipulating the whitespace between and within lists

%----------------------------------------------------------------------------------------
%	TITLE AND AUTHOR(S)
%----------------------------------------------------------------------------------------

\title{\normalfont\spacedallcaps{Virtual Watershed Platform}} % The article title

\subtitle{\normalfont\spacedallcaps{Plan for 2015: Optimize the Whole}} % The article title

\author{\spacedlowsmallcaps{Matthew A. Turner*}} % The article author(s) - author affiliations need to be specified in the AUTHOR AFFILIATIONS block

%----------------------------------------------------------------------------------------
%	HYPERLINKS
%---------------------------------------------------------------------------------------
\usepackage{hyperref}
\hypersetup{
%draft, % Uncomment to remove all links (useful for printing in black and white)
colorlinks=true, breaklinks=true, bookmarks=true,bookmarksnumbered,
urlcolor=webbrown, linkcolor=RoyalBlue, citecolor=webgreen, % Link colors
pdftitle={Virtual Watershed Platform, Plan for 2015: Optimize the Whole}, % PDF title
pdfauthor={\textcopyright}, % PDF Author
pdfsubject={}, % PDF Subject
pdfkeywords={}, % PDF Keywords
pdfcreator={pdfLaTeX}, % PDF Creator
pdfproducer={LaTeX with hyperref and ClassicThesis} % PDF producer
}

\begin{document}
\maketitle % Print the title/author/date block

\setcounter{tocdepth}{2} % Set the depth of the table of contents to show sections and subsections only

\tableofcontents % Print the table of contents
\section*{abstract}

We are in a position to create a very interesting and useful web app for watershed scientists.
The WC-WAVE project itself is ambitious enough in its scope to be of interest to 
Michael O'Rourke and Sanford Eigenbrode to study. Like a childhood game of telephone, not 
only is there confusion about our goals 
between the cyberinfrastructure and watershed science teams, but also
within individuals of the cyberinfrastructure group. This document will serve as a reference
document of how we plan to go forward as the year progresses. 
It will identify the commonalities
in the user stories we have gathered and suggest some goals and direction based on that.

In short, I propose we make a useful product that watershed scientists actually want to use
as rapidly as possible. We will build quality in by employing test-driven development and 
integrating user feedback as we gather it. Maybe the most important "product" we'll produce
is knowledge generated from creating this software. In
this spirit, we also must make sure all the software we produce is well-documented, and publicly 
available and installable/runnable. We will optimize the whole by focusing on 
the user experience and letting the functionality we build flow from that.

{\let\thefootnote\relax\footnotetext{* \textit{Northwest Knowledge Network, 
University of Idaho}}}



\newpage
     

\section{Introduction: Historical View} % (fold)
\label{sec:intro}

We recently completed a meeting of the entire Western Consortium, which allowed us to get
feedback on the virtual watershed platform and better understand the watershed scientists needs.
The Track 2 WC-WAVE Proposal says in its "Project Summary" (Page A), that the watershed scientists
will "specify VW user requirements; and provide feedback on the evolving CI platform." However, 
their requirements should be tempered by another responsibility outlined in the same place, that
"Watershed scientists and students will parameterize, run, validate, and integrate watershed models".

Amidst all this ambiguity of what the virtual watershed (platform) is and should be, 
this document will hopefully enable us to have a reference for our common focus. The UNM folks have
done an excellent job building a virtual watershed that provides a lot of great core functionality.
With a few of the upgrades we've identified, it will be a powerful tool for the backbone of a system
that allows watershed researchers and students to search for peer-reviewed and published datasets,
visualize the results of their experiments via its WMS services, and provide data to models to the
specifications of researchers seeking to work with input or output data locally, or to build new 
models that they can later upload to the virtual watershed! For starting out, we'll focus on 
data that's already published and publicly available. 

In the rest of the introduction, we'll examine what's already been accomplished, and then provide
a vision for our next year of work. 

\subsection{Virtual Watershed} % (fold)
\label{sub:vw}

The virtual watershed is, at its core, a database. Except that it's built on three different
databases because there are two levels of metadata to serve and search, and still the data itself
to serve and ingest. The front end is built on the Python framework \href{http://www.pylonsproject.org/}{Pyramid}.
The Virtual Watershed team built a simple yet powerful REST API to search, upload and insert, and download
hydrological data. For example to get all the model runs named \texttt{climate\_scenario\_plus\_one} within
a nine day period from October 10 to October 19, 2010, 
navigate to 
\href{https://129.24.196.28/apps/my\_app/search/datasets.json?version=3\&start\_model\_run\_name=outputsP4.0\&timestamp\_start=2010-10-11T00:00:00\&timestamp\_end=2010-10-19T00:00:00}{https://129.24.196.28/apps/my\_app/\\search/datasets.json?version=3\&start\_model\_run\_name=outputsP4.0 \\ \&timestamp\_start=2010-10-11T00:00:00\&timestamp\_end=2010-10-19T00:00:00} 
in your browser. No authentication is needed to search.

Uploading and inserting data can be done using a POST or a PUT request, respectively, as
demonstrated in \ref{lst:vw}. Specifically,
this means first uploading some data to the VW storage. To make that data discoverable, 
it's required to then \textit{insert} the associated watershed metadata. This
requires authentication. Here is how uploading and inserting is done, assuming that \texttt{metadata} is a 
metadata string and \texttt{file.nc} is the file to be uploaded. We intentionally leave some details out,
just to give a flavor of the API structure for this document.
\begin{listing}
    \caption{Direct use of the Virtual Watershed API}
\begin{minted}[frame=lines]{python}
import requests

# must provide model_run_uuid; leaving out details, see API docs:
# https://www.northwestknowledge.net/AdaptorDocs/watershed.html
model_run_uuid = "7a79b86d-2857-47b3-8329-aec8ee5e4749"

upload_file = "file_to_upload.nc"

data_payload = {'name': os.path.basename(upload_file),
               'modelid': model_run_uuid}

# upload file               
data_upload_url = "https://129.24.196.28/apps/my_app/data"
requests.post(data_upload_url, data=data_payload,
              files={'file': open(upload_file, 'rb')},
              auth=(uname, passwd), verify=False)

# insert metadata contained in metadata_string
insert_metadata_url = "https://129.24.196.28/apps/my_app/datasets"
result = requests.put(insert_metadata_url,
                      data=metadata_string,
                      auth=(uname, passwd),
                      verify=False)
\end{minted}
\label{lst:vw}
\end{listing}

% subsection  (end)
\subsection{Adaptors} % (fold)
\label{sub:adaptors}

The adaptors in their current state provide a simplified Python API to wrap the web API provided
by the Virtual Watershed. They help watershed users complete common tasks that are actually rather
data intensive when you consider just how much metadata must accompany every file.

In their future iteration, we were imagining there would be an adaptor for every model or between
requested models. Though the next two adaptors on the horizon are the "human" adaptor, the web app, 
and adaptors to serve watershed data, which will be standardized to serve .nc files. Thus, there is
no reason at this point to create adaptors between models, only between models and the watershed.
This simplifies our task since there are some common input formats between models. This is 
the "data-centric" model coupling model.

To illustrate the Adaptors, \ref{lst:adaptor} shows an example of how 
the adaptors simplify the use of the watershed.
Instead of manually entering information like the data upload URL or manually building a 
search URL, the adaptors make use of configuration files parsed using   
\href{https://docs.python.org/2/library/configparser.html}{ConfigParser} 
from Python's standard library.

\begin{listing}
    \caption{Identical requests using the virtual watershed adaptor API}
    \begin{minted}[frame=lines]{python}
from adaptors.watershed import default_vw_client

# initialize a virtual watershed client; authentication is checked here as well
vw_client = default_vw_client()  # reads file 'default.conf' in current directory

# perform identical search; search_results is a QueryResult
# https://www.northwestknowledge.net/AdaptorDocs/watershed.html#watershed.QueryResult
search_results = vw_client.search(start_model_run_name="outputsP4.0", 
                                  timestamp_start="2010-10-11T00:00:00",
                                  timestamp_end="2010-10-19T00:00:00")

# upload the file from previous example
vw_client.upload(model_run_uuid, upload_file)

# insert metadata
json_metadata = metadata_from_file(upload_file, model_run_uuid, 
                                   model_run_uuid, "Description of the dataset")
vw_client.insert_metadata(json_metadata)
\end{minted}
\label{lst:adaptor}
\end{listing}
% subsection subsection name (end)


\subsection{January Meeting} % (fold)
\label{sub:January Meeting}

% subsection January Meeting (end)

Here are a few paraphrased things I heard at the January meeting:

\begin{itemize}
    \item "So do models run in the Virtual Watershed and if so, how does that work?"
    \item "How can I run HPC-dependent models with the Virtual Watershed?"
    \item (In reference to an IPython demo of the watershed) "Are you sure you wanna show that?"
    \item "I want to be able to arbitrarily use climate forecasts as drivers for my model"
    \item "I want to be able to use inputs gathered for one model in another model"
    \item "Can I track which model is which with the virtual watershed?"
\end{itemize}

With all these competing requests combined with our (CI-Data/Vis) expectations and understanding
of what the watershed scientists expect from the Virtual Watershed, it is no surprise that
there is a lot of confusion around the meaning and purpose of "Virtual Watershed". So let me
propose some definitions that are by no means permanent, but necessary for an intelligible discussion
of how we will make our next round of progress.

\begin{itemize}
    \item \textbf{Virtual Watershed (VW):} a system for intelligently storing 
        \href{http://www.unidata.ucar.edu/software/netcdf/}{netCDF} files and serving
        a variety of output formats. 
    \item \textbf{Adaptors:} Software to facilitate the use of VW-served data. This software may
        be for direct human-VW interaction, VW-model (e.g. using VW-served data as parameters and 
        forcing variables) interaction, or model-to-model, VW-mediated (data-centric) model 
        coupling
    \item \textbf{Virtual Watershed Platform (VWP):} The mythical beast that researchers are
        clamoring for. An interactive platform where researchers can search for and download data,
        upload their data to the virtual watershed, and run models that are available for a given
        dataset.
\end{itemize}

To address all these competing demands and confusions, I propose the following way forward:

At a minimum, we provide the web interface that many researchers would like. I propose we
copy David Tarboton's idea for \href{http://www.iemss.org/sites/iemss2014/papers/iemss2014_submission_243.pdf}{HydroShare}, 
which is to have an interface like YouTube but for watershed data. Below is a wireframe idea
that we can target first. I imagine we can make something like this happen in about six months. 
Of course it will take work, but we have some time, and if we focus on making a next-generation
\textit{easy-to-use} framework, we will make a unique contribution to the wellspring of such tools
aimed at enabling earth science activities in general. Here's how I propse we make that happen.

\includepdf{vw_lab_wireframe}

\subsection{Plan and Feature Specifications} % (fold)
\label{sub:Plan}

In that wireframe, there are three separate tasks that need to be done, which can be shared
between UNM, UNR, and UI. As a design principle, I want this interface to be lightweight and to
use a common foundation. Personally, I'm going to use 
\href{http://flask.pocoo.org/docs/0.10/}{Flask}, a Python module for building web apps. There is
also the Pyramid framework that the UNM team is using for the Virtual Watershed, and there's 
also a promising \href{http://www.django-rest-framework.org/}{Django REST framework}. For now,
the particular implementation is not important. If anything, we'd benefit from exploring just what
different frameworks have to offer. The app architecture I propose would both provide
an immediately useful tool for collaboration and data discovery and visualization, 
but also be feature-scalable, meaning we could readily add things like model execution, HPC 
facilitation, or interactive data modification.

The work can be split roughly in two: the backend of the VWP (the virtual watershed itself),
and the user-facing web app and Python API (adaptors, each in its own way). There had been talk
of John Erickson contributing to web submission of data to the VW, and that is fine and welcome.
It's more about backend/frontend separation.

\subsubsection{University of New Mexico: Virtual Watershed} % (fold)
\label{ssub:UNM_webtool}

At this point in the project, we have put a lot of pressure on the UNM team to make progress
on various fronts to improve the already-impressive virtual watershed. Let me recap the 
development goals for the next quarter here:

\begin{enumerate}
    \item Make netCDF the base format for all VW-hosted data
    \item Expand the functionality such as providing DELETE and returning 
    \item Provide a user interface for submitting new data to the VW
\end{enumerate}

In addition to these, I would add:

\begin{enumerate}
    \item Host production code in the \texttt{master} branch of the \href{https://github.com/tri-state-epscor/virtual-watershed}{virtual-watershed repository}
    \item Include docs on how to install one's own instance of the virtual watershed for local 
        testing and experimentation
    \item Unit tests for the virtual watershed. This is a key element of knowledge creation.
\end{enumerate}

% subsubsection University of Mexico: Virtual Watershed and Submit Web Tool (end)

\subsubsection{UI and UNR: User-facing elements of the virtual watershed platform} % (fold)
\label{ssub:user-facing}

I am in touch with quite a few watershed scientists to continually update our view of what
a useful product is for them. Because of this, I've decided to take on the lead for 
producing the browsing page that I've included in the wire frame. I plan on doing some 
shape-shifting as I've had requests to provide new infrastructure for modellers, and I have 
more hands-on knowledge of running the models. I think we'll have a UI/UNR 
direct collaboration that will have weekly team meetings to check in on progress.

I believe the web app as described above in the wireframe is in line with 
the imperative from the Project Summary, for the Visualization and Data CI component
to "Accelerate collaborative, interdisciplinary watershed research
and discovery through innovative visualization environments and through streamlined
data management, discovery, and access. 

Such an app will naturally be able to integrate features like the ability to run models 
as a web service. This will mean that
on being called, the service will fetch the input data as requested from the VW, save the input
data to the appropriate location on disk, run the model giving updates as it progresses, and 
finally making the output data available for download or visualization via the virtual watershed
laboratory browse page where the model run began.

Using the adaptors, this might be done something like this 
(see 
\href{http://stackoverflow.com/questions/15182696/multiple-parameters-in-in-flask-approute}{this helpful Stack Overflow answer}):

\begin{listing}
    \caption{Sketch of the use of Flask for models-as-a-service}
\begin{minted}[frame=lines]{python}
    from flask import Flask
    from adaptors.watershed import default_vw_client

    app = Flask(__name__)
    vw_client = default_vw_client()

    @app.route("/models/isnobal", methods=['GET'])
    def run_isnobal():
        input_uuid = request.args.get('input_uuid')
        download_urls = vw_client.search(model_run_uuid=input_uuid)
        for url in download_urls:
            download_inputs(url)

    @app.route("/models")
    def show_models_doc():
        return MODELS_DOC  # a static documentation string of html and/or js
\end{minted}
\label{lst:demo_app}
\end{listing}

Speaking of the adaptors, there is still plenty to do there. The data and vis CI teams are in
touch with folks at UNR about creating adaptors for PRMS. Although I had no plan of how 
adaptor development would be distributed, if CI teams can actually have face-to-face interactions
with watershed teams, that seems preferable.

% subsubsection University of Nevada: Models as a Service (end)
\section{Design Philosophy} % (fold)
\label{sec:design_philosophies}
The design plans above are guided by some design philosophies which are wisely reviewed in 
Mary and Tom Poppendieck's \textit{Implementing Lean Software Development}. The "seven
principles of lean software development" and some notes on how they apply to our project are:

\begin{enumerate}
    \item Eliminate Waste
        \begin{itemize}
            \item Difficult for us, because a year in our goals and requirements still aren't clear
        \end{itemize}
    \item Build Quality In
        \begin{itemize}
            \item Do this with unittests and get users using our platform ASAP
        \end{itemize}
    \item Create Knowledge
        \begin{itemize}
            \item Arguably our main "product" here is the addition of what we (CI-Data/Vis) have 
                learned in building the software backbone of this interdisciplinary project
            \item This requires publicly available software with reliable documentation
            \item We need detailed plans and weekly reports within our teams
        \end{itemize}
    \item Defer Commitment
        \begin{itemize}
            \item Myth: planning is commitment. D.D. Eisenhower: "In war plans are useless but 
                planning is indispensible"
            \item By deferring commitment to specific models or model interactions, we free 
                ourselves to deliver incremental products fast
        \end{itemize}
    \item Deliver Fast
        \begin{itemize}
            \item By delivering fast we initiate a more rapid user feedback/product improvement loop
        \end{itemize}
    \item Respect People
        \begin{itemize}
            \item Hopefully we can all fill our roles as well as ask for help or raise flags when
                some part is too much. Anyone can "stop the line".
        \end{itemize}
    \item Optimize the Whole
        \begin{itemize}
            \item By focusing on the wireframe and a larger-scale plan, we avoid prematurely
                optimizing a subunit of the VWP
        \end{itemize}
\end{enumerate}
% section design_philosophies (end)

\section{Science Situation} % (fold)
\label{sec:science}

\subsection{tl;dr} % (fold)
\label{sub:tl;dr}

At this point, I propose we delay committing to specific scientific applications beyond
running models for which we have fully-built inputs. If we do this well, extending our
functionality to some more interactive modifications, and even the mega-bonus goal of
arbitrary model coupling, will fit in naturally to the architecture we build today.


% subsection tl;dr (end)

\subsection{Justification and details} % (fold)
\label{sub:Justification and details}

% subsection Justification and details (end)

As I've already said, our customers are the watershed scientists and modelers. Our product
should serve them. I think at a minimum, the web app that I've described above, though 
simple, would serve a purpose. It would allow researchers to publish their data and models,
allow others to run the model and interactively visualize the results, and with some 
modification, allow researchers or students to tweak parameters. However, if all we have
is a YouTube for watershed science, then some of the loftier goals that have been discussed,
for example arbitrarily coupling of climate and hydrological models, is not really possible.

In conversations with researchers doing things that sounded possible are actually not. 
I thought that it'd be possible to arbitrarily run an iSNOBAL model on some data that
was in a general format in the watershed, but originally curated for use in some other model.
This is not possible. Modellers speak of "building" specific, e.g. iSNOBAL or PRMS, models.
What this means is generating parameters that act as constants for the entire model run. 
An example parameter found in both PRMS and iSNOBAL is albedo, or the \href{https://www.esr.org/outreach/glossary/albedo.html}{fraction of solar energy (in the short wave) reflected back into space from Earth}. 
This constant is not the same for every watershed. It must not only be approximated,
but calibrated with human interaction. It may be automatable, but that is a difficult 
problem that we should consider outside of the scope of this project.

So then what is within the scope of our project? That is still an open question, but
according to John Volk, once a model is "built" it may be possible to modify certain 
inputs, like temperature. Research would be needed on the details of each model for
the proper way to do this, but this would at least serve an educational purpose. New students
of hydrology and modeling could interactively play with these hosted models and model 
forcings. One modeller in the PRMS/Watershed Hydrology Giants group thought that 
an interactive map with the ability to change the vegetation type (a code from 0 - 4 for the
increasing extent of cover). 

% section science (end)

\bibliographystyle{apa}
\bibliography{bibliography}
\end{document}
